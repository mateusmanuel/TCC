%\part{Referencial Teórico} 
\chapter[Referencial Teórico]{Referencial Teórico} \label{referencialteorico} 
Esse capítulo apresenta, em linhas gerais os elementos necessários para o entendimento da proposta desse trabalho. Inicialmente será apresentado o que são problemas de otimização e como eles se caracterizam (Seção~\ref{sec:probOtimizacao}) seguido pela definição e exemplificação de meta-heurísticas (Seção~\ref{sec:metaheuristica}). Por fim, os conceitos relacionados à geração de dados de teste sob a perspectiva de SBST serão apresentados na Seção~\ref{sec:trabsSBST}, seguidos pelas consideraçes finais desse capítulo (Seção \ref{sec:considFinRefTeor}).  




\section{Problema de otimização \label{sec:probOtimizacao}}

A otimização é um termo que vem da matemática que, em sua essência, está
preocupada com a obtenção das condições que dão o valor extremo de uma ou de
várias funções sob determinadas circunstâncias (referencia?). A definição formal
matemática pode ser definida como: 

\begin{eqnarray}
\label{eqn01}
	 \textsf{Encontrar \textbf{x} que minimize \textbf{f(x)} sujeito a} \nonumber \\
     g_j(x) \leq 0, \qquad j = 1, 2, ..., n_g \\
\label{eqn02}
      h_k(x) = 0, \qquad k = 1, 2, ..., n_h \\
\label{eqn03}
      x_{i}^{L} \leq x_i \leq x_{i}^{U}, \qquad i = 1, 2, ..., n 
\end{eqnarray}
onde $x_{e}$ (onde $x_e$ na definição?) o vetor das $n$ variáveis de projeto, $f(x)$ é a função objetivo e $g_{j}(x)$ e $h_{k}(x)$ são as restrições de desigualdade e igualdade, respectivamente. Os limites das variáveis são determinados através da equação \ref{eqn03}, onde onde $x_{i}^{L}$ é o limite inferior e $x_{i}^{U}$ é o limite superior da variável $x_{m}$. Nas outras expressões, $n$, $n_{g}$ e $n_{h}$ são o número de variáveis de projeto, número de restrições de desigualdade e igualdade, respectivamente \cite{gandomi2013metaheuristic}.  

Na definição, a função objetivo (onde está a representação da função objetivo em termos de coeficientes e variáveis? Ela está apenas representada por $f(x)$) se refere ao que se quer maximizar ou minimizar (na definição está apenas minimizar), o conjunto de variáveis $x_i$ é o conjunto de valores que afeta o valor da função objetivo $f(x)$ e os conjuntos de restrições $g_j(x)$ e $h_j(x)$ são os conjuntos que não permitem que as variáveis do conjunto $x_i$ assumam determinados valores. Considerando tais elementos é possível classificar os problemas de otimização de acordo com as características de cada um desses elementos. Os possíveis valores que cada elemento pode assumir em tal classificação estão descritos na Figura~\ref{figotimizacao01}.

Os problemas típicos de otimização vão desde a minimização de funções algébricas
até assuntos mais práticos em projetos de engenharia tais como a minimização de
custos e a maximização de desempenho. A pergunta que todos esses problemas têm
em comum é ``Dentre as soluções viáveis, qual é a melhor?''. O meio que se busca
para respondê-la, após a definição das restrições e da função objetivo, é pela
utilização de algum método de otimização. Os métodos de otimização que se
ajustam a pergunta são os probabilísticos, no caso as heurísticas e
meta-heurísticas~\cite{gandomi2013metaheuristic}. (Frase introdutória das
meta-heurísticas que serão apresentadas nas subsecoes seguintes)

\begin{figure}[h]
	\centering
	\label{figotimizacao01}
    \tikzset{
        basic/.style  = {draw, text width=4cm, drop shadow, font=\sffamily, rectangle},
        root/.style   = {basic, rounded corners=2pt, thin, align=center,
                         fill=gray!60},
        onode/.style = {basic, thin, align=center, fill=gray!40,text width=4cm,},
        tnode/.style = {basic, thin, align=left, fill=gray!20, text width=6.5em},
        edge from parent/.style={-, >={latex}, draw=black, edge from parent fork right}
    }

    \begin{tikzpicture} [%
        grow=right,
        anchor=west,
        growth parent anchor=east,
        parent anchor=east,
        level 1/.style={sibling distance=6em},
        level 2/.style={sibling distance=2.5em},
        level distance=0.5cm]
    \node[root] (root) {Classificação dos problemas de otimização}
        child {node[onode] (c1) {Número de variáveis de projeto}
            child {node[tnode] (c11) {Única Variável}}
            child {node[tnode] (c12) {Multivariável}}
        }
        child {node[onode] (c2) {Número de funções objetivo}
            child {node[tnode] (c21) {Único Objetivo}}
            child {node[tnode] (c22) {Multiobjetivo}}
        }
        child {node[onode] (c3) {Presença de restrições}
            child {node[tnode] (c31) {Sem restrições}}
            child {node[tnode] (c32) {Com restrições}}
        }
        child {node[onode] (c4) {Tipo de variáveis de projeto}
            child {node[tnode] (c41) {Discreta}}
            child {node[tnode] (c42) {Contínua}}
            child {node[tnode] (c43) {Mista}}
        }
        child {node[onode] (c5) {Característica das restrições e da função objetivo}
            child {node[tnode] (c51) {Linear}}
            child {node[tnode] (c52) {Não-linear}}
        }
        child {node[onode] (c5) {Natureza das variáveis e dados de entrada}
            child {node[tnode] (c51) {Determinística}}
            child {node[tnode] (c52) {Probabilística}}
        };
    \end{tikzpicture}
    \caption{Classificação dos problemas de otimização. Adaptado de~\cite{gandomi2013metaheuristic}}
\end{figure}

\section{Meta-heurísticas \label{sec:metaheuristica}}

Os métodos de busca meta-heurísticos podem ser definidos como metodologias ou modelos de nível superior que podem ser usados como estratégias de orientação no projeto de heurísticas subjacentes para resolver problemas de otimização \cite{talbi2009metaheuristics}. Ser de nível superior significa que são algoritmos de propósito geral, enquanto as heurísticas são desenhadas e construídas para  problemas específicos. (frase muito autocontida... convém detalhar mais para explicar melhor seu conteúdo. tente explicar o que é estratégia de orientação no projeto de heurísticas subjacentes)

Como dito, elas costumam ser usadas como estratégia de orientação para o projeto de heurísticas derivadas. Isso expressa que normalmente elas são adaptadas de acordo com as restrições, as variáveis e à função objetivo do problema em questão. (Explicacao necessária para o paragrafo superior? me parece que complementa minha duvida mas ainda nao responde...)

Em uma meta-heurística são observados dois principais fatores: a investigação do espaço de busca (diversificação) e a exploração das melhores soluções encontradas (intensificação). (A ilustração desses fatores por um exemplo, cairia muito bem nesse ponto.) Esses fatores geralmente estão ligados ao tipo de solução em que as meta-heurísticas estão baseadas. As meta-heurísticas baseadas em solução única, tais como o recozimento simulado e a busca local, estão ligadas a intensificação (\textit{ie.} ao encontro de uma solução ótima com base na exploração das melhores soluções encontradas até então, ao passo que as meta-heurísticas baseadas na população, como algoritmos genéticos e a inteligência de enxame, estão relacionadas a diversificação \cite{talbi2009metaheuristics}.

As meta-heurísticas possuem uma grande variabilidade de classificação que vão além daqueles mostrados anteriormente. Um outro fator que pode ser citado é a inspiração, podendo ser baseada em processos da natureza (a grande maioria dos casos) e não-baseada em processos naturais. A maneira de decisão dos algoritmos classifica as meta-heurísticas em determinísticas e estocásticas em que regras aleatórias são aplicadas durante a busca (referencia???). Dado essa diversidade as meta-heurísticas Subida de Encosto, Recozimento Simulado,  Algoritmo Genético e Inteligência de Enxame ganham destaque, principalmente na área de Engenharia de Software \cite{khari2017extensive} por tratarem, principalmente, de problemas estocásticos. (As idéias contidas nesse parágrafo são muito interessantes e merecem serem exploradas em mais detalhes. O que é determinístico? Estocástico?  Por que a Engenharia de Software lida com problemas estocásticos? Informações obtidas como respostas às essas perguntas são valiosas e contribuem muito ao seu trabalho!).


\subsection{Subida de Encosta}
\label{sec:subidaDeEncosta}

O algoritmo de Subida de Encosta (\textit{Hill Climbing}) é um método simples que proporciona resultados rápidos e por isso é um dos algoritmos mais utilizados. Ele consiste em um busca local que investiga e substitui de forma contínua o valor crescente com relação aos valores vizinhos imediatos com o objetivo de alcançar o máximo global, ou seja, o maior valor. Durante a execução existir alguns problemas, como a identificação de um valor local mais alto, máximo local, porém ainda menor que o valor mais alto do espaço de estados. Outra dificuldade no algoritmo são os platôs, região do espaço de estados onde a função de avaliação é plana, gerando o mesmo resultado \cite{russell2016artificial}.

Assim sendo, o sucesso do algoritmo depende da topologia do espaço de estados. Uma adaptação bastante utilizada que mingua os problemas é a subida de encosta com reinício aleatório, onde se realiza uma série de buscas a partir de estados iniciais gerados aleatoriamente \cite{russell2016artificial}. 

A complexidade de algoritmo se restringe apenas ao tempo, visto que com relação ao espaço não se guarda uma árvore de busca, apenas o estado atual e o seu valor. Para a maioria dos problemas uma solução ótima pode ser obtida em tempo polinomial. Entretanto, se o número de máximos locais for alto o tempo computacional poder ser exponencial \cite{skiena1998algorithm}.

\subsection{Recozimento Simulado}

Recozimento Simulado (\textit{Simulated Annealing}) é um algoritmo similar à Subida de Encosta com a diferença que os movimentos no espaço de busca não são tão limitados (ANDRE: essas limitações são apresentadas na seção \ref{sec:subidaDeEncosta}?). Para a exploração do espaço de busca ele utiliza um parâmetro de controle denominado temperatura. Tal parâmetro é a probabilidade de aceitar as piores soluções, ou seja, soluções com menor valor de aptidão (Andre: o que é aptidão? O termo apareceu pela primeira vez aqui, convem defini-lo para o leitor).  Aceitar as piores soluções é uma propriedade fundamental porque possibilita uma busca mais extensiva para a solução ótima global \cite{kirkpatrick1983optimization}. (Andre: como se dá essa busca mais extensiva? Senti falta de uma explicação mais detalhada sobre...)

O método consiste em iniciar com um valor alto de temperatura (representando o que?) e à medida em que é aplicado o resfriamento (o que significa o resfriamento?), ou seja, a busca, a temperatura tende a diminuir até chegar a zero (quanto chega em zero, o que significa? Solução encontrada?). Tal como a Subida de Encosto, o Recozimento Simulado considera apenas uma solução por iteração e não realiza qualquer suposição sobre o panorama de soluções (mencionar busca local). Outro problema que possui igualmente à Subida de Encosto é a possibilidade de ficar preso em um ótimo local quando a temperatura esfria rapidamente (problema da busca local).

(ANDRE: vide seção 4.2 do artigo de \cite{youssef2001167}. Existe uma série de detalhes que podem auxiliar na explicação tanto de Recozimento Simulado, quanto demais algoritmos apresentados pelo artigo e pela dissertação.).


\subsection{Algoritmo genético}

Os Algoritmos Genéticos (\textit{Genetic Algorithms} - GA) partem da semelhança da codificação dos resultados de candidatos como uma série de componentes simples e o arranjo genético de um cromossomo \cite{alander1998genetic} (Sugiro explicar melhor o conteúdo dessa frase. O que é codificação de resultados de candidatos? O que seriam os componentes simples? Qual a relação de um arranjo genético de um cromossomo? Um exemplo ilustrativo cairia muito bem nessa seção.). Os resultados, nesse caso, geralmente se referem aos indivíduos (cromossomos) que utilizam essa meta-heurística (apresentar claramente esse paralelo: solução => cromossomo). Os possíveis valores para cada componente é chamado de alelo, a sua posição específica na sequência é denominada \textit{locus} e os constituintes do resultado são por vezes denotados como genes. (Explicar esses elementos através do exemplo... ficará muito mais claro).

A escolha de uma população inicial aleatória, \textit{i.e.}, um conjunto de cromossomos, é o primeiro passo do processo iterativo dos algoritmos genéticos.  As iterações, denominadas de gerações, terminam quando a condição pré-determinada (obscuro... explicar...) é atingida ou quando o número de gerações é excessivo. Em cada geração, cromossomos são recombinados cruzando seus genes. Uma parte da descendência dessa união sofre mutação e, à partir da prole e da população original, um processo de seleção é usado para determinar a nova população.  Crucialmente, a recombinação e a seleção são guiadas pela função objetivo; cromossomos mais aptos tendo uma chance maior de serem selecionados e recombinados.

(Os passos recombinação, mutação, avaliação e seleção foram citados no
capitulo 3, mas nao foram apresentados aqui no capítulo de referencial teórico.
Certificar de que foi feita sua apresentação.)


\subsection{Inteligência de Enxame}

A meta-heurística Inteligência de Enxame (\textit{Swarm Intelligence}) tem como base o modelo biológico com ênfase em como os indivíduos trabalham em conjunto com a distribuição de informações (referencia). As redes de fluxos de feromônios são o principal objetivo das formigas para decidir onde forragear. (Salto muito grande entre a primeira frase e as demais... as demais me parecem exemplificar...  talvez introduzir o exemplo). Se as formigas encontrarem aleatoriamente um obstáculo, elas procurarão métodos (métodos? não seriam caminhos?) ao redor. No entanto, quando certas formigas encontram uma maneira de contorná-lo, as outras formigas seguem sua pista de feromônio para criar uma nova rota.

A cooperação das formigas foi a primeira forma de organização biológica analisada. Porém, com o passar do tempo  outros métodos de otimização de inteligência de enxame surgiram tais como a Otimização por Enxame de Partículas (PSO), Otimização por Colônia de Abelhas (ABC) e a Otimização por Sistemas Artificiais Imunológicos (AIS) \cite{blum2008swarm}. Em todos esses tipos de otimização determinados comportamentos da colônia e de seus indivíduos são observados como um todo criando, assim, uma inteligência artificial própria que vai agregar (agregar o que?) e constituir a formulação da função objetivo do problema de otimização. As iterações vão obedecer as restrições biológicas do enxame escolhido (restricoes nao foram apresentadas no texto... apresentar).

\section{Geração de Dados de Teste de Software Baseada em Busca \label{sec:trabsSBST}}

As definições citadas anteriormente contribuem para o desenvolvimento da engenharia de software. Com tais, é possível observar a generalidade que se ganha com a representação de um problema e com a função objetivo, e a robustez que os algoritmos de otimização proporcionam \cite{harman2012search}. 

% Além disso, pode ser observada a escalabilidade através do paralelismo que as meta-heurísticas proporcionam, a reunificação de subáreas da engenharia de software e a computação direta dos problemas \cite{harman2012search}. Isso, devido ao software já estar representada de maneira lógica, diferente de outras engenharias, que precisam da simulação dos seus artefatos. Como por exemplo, a representação de um material físico, o que necessita de um alto poder computacional.

A otimização por busca se encontra difundida em testes pois é possível notar sua atuação em dimensões como estrutural (caixa branca), funcional (caixa-preta), uma mescla de ambos (caixa cinza) e não-funcional.  Entretanto, os testes estruturais foram os que mais receberam esforços para o desenvolvimento orientado a busca. Dentre os esforços empreendidos destacam-se aqueles que visam a geração de casos e dados de teste para a cobertura de caminhos possíveis na execução do software \cite{khari2017extensive}. (exemplificar os casos mais significativos apresentados no artigo \cite{khari2017extensive}).

A geração de dados para teste constituti na busca de valores para parametros de entrada que atendam a critérios de teste específicos. Estes valores de entrada podem assumir diferentes formas tais como parâmetros de uma função, parâmetros para uma sequência de chamadas de método, dentre outras. A finalidade que mais se almeja com a geração de dados é aumentar a cobertura de código de casos que demandariam um empenho grande do testador. (referencia?)

\subsection{Cobertura de Código}

A cobertura de teste é uma medida usada para descrever o grau em que o código-fonte de um programa é executado quando um determinado conjunto de testes é aplicado. Um programa com alta cobertura de teste, medido em porcentagem, tem o seu código-fonte mais executado durante o teste, o que sugere que ele tem uma chance menor de conter erros de software não detectados em comparação com um programa com baixa cobertura de teste \cite{yang2009survey}. Muitas métricas diferentes podem ser usadas para calcular a cobertura de teste; algumas das mais básicas são a porcentagem de sub-rotinas de programa e a porcentagem de declarações de programa chamadas durante a execução do conjunto de testes.

\subsection{Teste Multiobjetivo Baseado em Busca}

A princípio os casos de testes era individuais, ou seja, as funções de
adaptação era construídas com base no caminho em que seria percorrido.
Recentemente propõe-se testes com multiobjetivos devido a, principalmente, pela
crescente estudo de aspectos não-funcionais nos testes. (Referencia)

(Aumentar essa seção significativamente...)









%\section{Consideraçoes finais \label{sec:considFinRefTeor}}



